{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fb98cb",
   "metadata": {},
   "source": [
    "## Next-VolumeMap Prediction with Convolutional LSTMs \n",
    "\n",
    "> * https://www.youtube.com/watch?v=fmga0i0MXuU&feature=youtu.be \n",
    "> * Code: https://github.com/lukas/ml-class/tree/master/videos/video-predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97872ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import h3\n",
    "import json\n",
    "import folium\n",
    "from geojson.feature import *\n",
    "import branca.colormap as cm \n",
    "from folium import Map, Marker, GeoJson \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90f725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import io\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import widgets, Layout, HBox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218acd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_columns = ['date', 'from_lat', 'from_lon', 'status', 'geozone_id']\n",
    "\n",
    "incoming_orders = pd.read_csv(\"mytaxi_test_max_taxi_incoming_orders.csv\", usecols=use_columns)\n",
    "\n",
    "incoming_orders = incoming_orders[incoming_orders.status == 7][:]\n",
    "# incoming_orders = incoming_orders[incoming_orders.geozone_id == 3][:]   \n",
    "\n",
    "incoming_orders.drop(columns=['status', 'geozone_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea2a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexagons_gridDF = pd.read_csv(\"hexagons_grid.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98b8b46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2021-01-01 00:01:06\n",
      "Max date: 2022-02-28 23:59:21\n"
     ]
    }
   ],
   "source": [
    "incoming_orders['date'] = incoming_orders['date'].astype('datetime64[ns]')  \n",
    "\n",
    "print(\"Min date: {}\".format(incoming_orders['date'].min()))\n",
    "print(\"Max date: {}\".format(incoming_orders['date'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2ac6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume_map(df, hex_df): \n",
    "    ## only keeping long, lat \n",
    "    \n",
    "    if df.shape[0] > 0: \n",
    "        df = df[[\"from_lat\", \"from_lon\"]] \n",
    "\n",
    "        df[\"hex_id\"] = df.apply(lambda row: h3.geo_to_h3(row[\"from_lat\"], row[\"from_lon\"], resolution), axis = 1) \n",
    "\n",
    "        df = df.groupby(by = \"hex_id\").size().reset_index() \n",
    "        df.columns = [\"hex_id\", \"value\"] \n",
    "\n",
    "        ### merging with hex_df \n",
    "        df = pd.merge(hex_df, df, on='hex_id', how='left')  \n",
    "        df.fillna(0, inplace=True) \n",
    "\n",
    "        ### sort \n",
    "        df.sort_values(by='hex_id', inplace=True)  \n",
    "\n",
    "        ### generating 28x28 numpy volume map  \n",
    "        volume_map = df['value'].values.reshape((28, 28)) \n",
    "    else: \n",
    "        volume_map = np.zeros((28, 28))\n",
    "\n",
    "    return volume_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d876bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 10 \n",
    "\n",
    "volume_maps = np.load(\"volume_maps_interval_{}.npy\".format(interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fcf1993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61055"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(volume_maps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41f77c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = volume_maps[:60000]   ## for train: 4000 frames \n",
    "test  = volume_maps[60000:]   ## for test: 415 frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db788bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(data, sequence_length): \n",
    "    main_list = [] \n",
    "    \n",
    "    for i in range(len(data) - sequence_length): \n",
    "        l = data[i:i+sequence_length]\n",
    "        l = np.array(l)\n",
    "        main_list.append(l)\n",
    "    \n",
    "    return np.array(main_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe439d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Shape of train sequence: (59995, 5, 28, 28, 1)\n",
      "[!] Shape of test sequence:  (1050, 5, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 5 \n",
    "\n",
    "train_dataset = make_sequence(train, sequence_length)\n",
    "test_dataset  = make_sequence(test, sequence_length)\n",
    "\n",
    "# Add a channel dimension since the images are grayscale.\n",
    "train_dataset = np.expand_dims(train_dataset, axis=-1)\n",
    "test_dataset  = np.expand_dims(test_dataset, axis=-1)\n",
    "\n",
    "print(\"[!] Shape of train sequence: {}\".format(train_dataset.shape))\n",
    "print(\"[!] Shape of test sequence:  {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82568f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying volume maps for example 59340.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct a figure on which we will visualize the images.\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 8))\n",
    "\n",
    "# Plot each of the sequential images for one random data example.\n",
    "data_choice = np.random.choice(range(len(train_dataset)), size=1)[0]\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Volume map {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Print information and display the figure.\n",
    "print(f\"Displaying volume maps for example {data_choice}.\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3583c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_frames(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, 4 : data.shape[1], :, :]\n",
    "    return x, np.squeeze(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c79bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to the 0-1 range.\n",
    "train_dataset = train_dataset / 255\n",
    "test_dataset = test_dataset / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6b8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K \n",
    "\n",
    "# Function for measuring how similar two images are\n",
    "def perceptual_distance(y_true, y_pred):\n",
    "    y_true *= 255.\n",
    "    y_pred *= 255.\n",
    "    rmean = (y_true[:, :, :, 0] + y_pred[:, :, :, 0]) / 2\n",
    "    r = y_true[:, :, :, 0] - y_pred[:, :, :, 0]\n",
    "    g = y_true[:, :, :, 0] - y_pred[:, :, :, 0]\n",
    "    b = y_true[:, :, :, 0] - y_pred[:, :, :, 0]\n",
    "\n",
    "    return K.mean(K.sqrt((((512+rmean)*r*r)/256) + 4*g*g + (((767-rmean)*b*b)/256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "069e025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shapes: (59995, 4, 28, 28, 1), (59995, 28, 28, 1)\n",
      "Validation Dataset Shapes: (1050, 4, 28, 28, 1), (1050, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Apply the processing function to the datasets.\n",
    "x_train, y_train = create_shifted_frames(train_dataset)\n",
    "x_val, y_val = create_shifted_frames(test_dataset)\n",
    "\n",
    "# Inspect the dataset.\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
    "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "637f0fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59995 samples, validate on 1050 samples\n",
      "Epoch 1/35\n",
      "59995/59995 [==============================] - 453s 8ms/step - loss: 0.0030 - perceptual_distance: 9.2256 - val_loss: 4.3596e-06 - val_perceptual_distance: 0.6550\n",
      "Epoch 2/35\n",
      "59995/59995 [==============================] - 448s 7ms/step - loss: 1.2227e-05 - perceptual_distance: 1.0757 - val_loss: 2.1510e-06 - val_perceptual_distance: 0.3964\n",
      "Epoch 3/35\n",
      "59995/59995 [==============================] - 471s 8ms/step - loss: 3.1365e-06 - perceptual_distance: 0.5500 - val_loss: 1.9640e-06 - val_perceptual_distance: 0.3351\n",
      "Epoch 4/35\n",
      "59995/59995 [==============================] - 457s 8ms/step - loss: 1.9635e-06 - perceptual_distance: 0.4321 - val_loss: 2.7577e-06 - val_perceptual_distance: 0.6060\n",
      "Epoch 5/35\n",
      "59995/59995 [==============================] - 469s 8ms/step - loss: 2.0569e-06 - perceptual_distance: 0.4200 - val_loss: 1.8475e-06 - val_perceptual_distance: 0.3256\n",
      "Epoch 6/35\n",
      "59995/59995 [==============================] - 479s 8ms/step - loss: 1.4651e-06 - perceptual_distance: 0.3591 - val_loss: 1.8551e-06 - val_perceptual_distance: 0.3628\n",
      "Epoch 7/35\n",
      "59995/59995 [==============================] - 476s 8ms/step - loss: 1.4298e-06 - perceptual_distance: 0.3523 - val_loss: 1.8973e-06 - val_perceptual_distance: 0.5357\n",
      "Epoch 8/35\n",
      "59995/59995 [==============================] - 474s 8ms/step - loss: 1.4615e-06 - perceptual_distance: 0.3535 - val_loss: 1.8710e-06 - val_perceptual_distance: 0.3790\n",
      "Epoch 9/35\n",
      "59995/59995 [==============================] - 473s 8ms/step - loss: 1.4180e-06 - perceptual_distance: 0.3546 - val_loss: 1.8455e-06 - val_perceptual_distance: 0.2767\n",
      "Epoch 10/35\n",
      "59995/59995 [==============================] - 473s 8ms/step - loss: 1.4044e-06 - perceptual_distance: 0.3555 - val_loss: 1.9135e-06 - val_perceptual_distance: 0.4637\n",
      "Epoch 11/35\n",
      "59995/59995 [==============================] - 477s 8ms/step - loss: 1.3999e-06 - perceptual_distance: 0.3572 - val_loss: 1.7878e-06 - val_perceptual_distance: 0.3985\n",
      "Epoch 12/35\n",
      "59995/59995 [==============================] - 475s 8ms/step - loss: 1.3809e-06 - perceptual_distance: 0.3513 - val_loss: 1.8241e-06 - val_perceptual_distance: 0.4539\n",
      "Epoch 13/35\n",
      "59995/59995 [==============================] - 475s 8ms/step - loss: 1.3863e-06 - perceptual_distance: 0.3513 - val_loss: 1.8004e-06 - val_perceptual_distance: 0.4233\n",
      "Epoch 14/35\n",
      "59995/59995 [==============================] - 473s 8ms/step - loss: 1.3890e-06 - perceptual_distance: 0.3518 - val_loss: 1.7972e-06 - val_perceptual_distance: 0.4087\n",
      "Epoch 15/35\n",
      "59995/59995 [==============================] - 477s 8ms/step - loss: 1.3761e-06 - perceptual_distance: 0.3470 - val_loss: 1.9496e-06 - val_perceptual_distance: 0.4067\n",
      "Epoch 16/35\n",
      "59995/59995 [==============================] - 476s 8ms/step - loss: 1.3745e-06 - perceptual_distance: 0.3466 - val_loss: 1.8842e-06 - val_perceptual_distance: 0.4961\n",
      "Epoch 17/35\n",
      "59995/59995 [==============================] - 476s 8ms/step - loss: 1.3476e-06 - perceptual_distance: 0.3532 - val_loss: 1.7165e-06 - val_perceptual_distance: 0.3715\n",
      "Epoch 18/35\n",
      "59995/59995 [==============================] - 478s 8ms/step - loss: 1.3375e-06 - perceptual_distance: 0.3495 - val_loss: 1.7541e-06 - val_perceptual_distance: 0.4114\n",
      "Epoch 19/35\n",
      "59995/59995 [==============================] - 473s 8ms/step - loss: 1.3238e-06 - perceptual_distance: 0.3493 - val_loss: 1.7641e-06 - val_perceptual_distance: 0.3241\n",
      "Epoch 20/35\n",
      "59995/59995 [==============================] - 477s 8ms/step - loss: 1.3090e-06 - perceptual_distance: 0.3570 - val_loss: 1.8839e-06 - val_perceptual_distance: 0.4787\n",
      "Epoch 21/35\n",
      "59995/59995 [==============================] - 477s 8ms/step - loss: 1.2803e-06 - perceptual_distance: 0.3555 - val_loss: 1.7690e-06 - val_perceptual_distance: 0.3650\n",
      "Epoch 22/35\n",
      "59995/59995 [==============================] - 476s 8ms/step - loss: 1.2777e-06 - perceptual_distance: 0.3550 - val_loss: 1.6400e-06 - val_perceptual_distance: 0.3783\n",
      "Epoch 23/35\n",
      "59995/59995 [==============================] - 472s 8ms/step - loss: 1.2751e-06 - perceptual_distance: 0.3560 - val_loss: 1.7686e-06 - val_perceptual_distance: 0.4988\n",
      "Epoch 24/35\n",
      "59995/59995 [==============================] - 448s 7ms/step - loss: 1.2700e-06 - perceptual_distance: 0.3543 - val_loss: 1.6295e-06 - val_perceptual_distance: 0.3554\n",
      "Epoch 25/35\n",
      "59995/59995 [==============================] - 449s 7ms/step - loss: 1.2703e-06 - perceptual_distance: 0.3541 - val_loss: 1.7475e-06 - val_perceptual_distance: 0.4770\n",
      "Epoch 26/35\n",
      "59995/59995 [==============================] - 444s 7ms/step - loss: 1.2594e-06 - perceptual_distance: 0.3522 - val_loss: 1.7704e-06 - val_perceptual_distance: 0.5219\n",
      "Epoch 27/35\n",
      "59995/59995 [==============================] - 448s 7ms/step - loss: 1.2561e-06 - perceptual_distance: 0.3509 - val_loss: 1.8126e-06 - val_perceptual_distance: 0.4907\n",
      "Epoch 28/35\n",
      "59995/59995 [==============================] - 448s 7ms/step - loss: 1.2520e-06 - perceptual_distance: 0.3502 - val_loss: 1.6441e-06 - val_perceptual_distance: 0.3945\n",
      "Epoch 29/35\n",
      "59995/59995 [==============================] - 448s 7ms/step - loss: 1.2474e-06 - perceptual_distance: 0.3489 - val_loss: 1.9761e-06 - val_perceptual_distance: 0.6621\n",
      "Epoch 30/35\n",
      "59995/59995 [==============================] - 451s 8ms/step - loss: 1.2450e-06 - perceptual_distance: 0.3479 - val_loss: 1.6799e-06 - val_perceptual_distance: 0.4569\n",
      "Epoch 31/35\n",
      "59995/59995 [==============================] - 445s 7ms/step - loss: 1.2429e-06 - perceptual_distance: 0.3476 - val_loss: 1.7650e-06 - val_perceptual_distance: 0.3682\n",
      "Epoch 32/35\n",
      "59995/59995 [==============================] - 448s 7ms/step - loss: 1.2434e-06 - perceptual_distance: 0.3470 - val_loss: 2.4105e-06 - val_perceptual_distance: 0.6116\n",
      "Epoch 33/35\n",
      "59995/59995 [==============================] - 446s 7ms/step - loss: 1.2377e-06 - perceptual_distance: 0.3439 - val_loss: 1.8686e-06 - val_perceptual_distance: 0.6093\n",
      "Epoch 34/35\n",
      "59995/59995 [==============================] - 449s 7ms/step - loss: 1.2369e-06 - perceptual_distance: 0.3444 - val_loss: 1.6194e-06 - val_perceptual_distance: 0.3850\n",
      "Epoch 35/35\n",
      "59995/59995 [==============================] - 447s 7ms/step - loss: 1.2370e-06 - perceptual_distance: 0.3434 - val_loss: 1.6527e-06 - val_perceptual_distance: 0.4585\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4, 28, 28, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lstm1 (ConvLSTM2D)         (None, 4, 28, 28, 4) 736         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 28, 28, 4) 16          conv_lstm1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 4, 14, 14, 4) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_lstm3 (ConvLSTM2D)         (None, 4, 14, 14, 8) 3488        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 14, 14, 8) 32          conv_lstm3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 4, 7, 7, 8)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_lstm4 (ConvLSTM2D)         (None, 4, 7, 7, 16)  13888       time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 4, 14, 14, 16 0           conv_lstm4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_lstm5 (ConvLSTM2D)         (None, 4, 14, 14, 16 18496       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 14, 14, 16 64          conv_lstm5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_lstm6 (ConvLSTM2D)         (None, 4, 14, 14, 8) 6944        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 14, 14, 8) 32          conv_lstm6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 14, 14, 8) 0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4, 14, 14, 8) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 4, 28, 28, 8) 0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 28, 28, 1, 4) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_lstm7 (ConvLSTM2D)         (None, 28, 28, 4)    1744        time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 28, 28, 1)    0           permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 4)    16          conv_lstm7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 5)    0           lambda_2[0][0]                   \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 1)    6           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 45,462\n",
      "Trainable params: 45,382\n",
      "Non-trainable params: 80\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Reshape, Permute, Input, add, Conv3D, GaussianNoise, concatenate\n",
    "from keras.layers import ConvLSTM2D, BatchNormalization, TimeDistributed, Add\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, UpSampling2D\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "def slice(x):\n",
    "    return x[:,:,:,:, -1]\n",
    "\n",
    "# wandb.init(config=hyperparams)\n",
    "# config = wandb.config\n",
    "\n",
    "c=4\n",
    "\n",
    "inp = Input((4, 28, 28, 1))\n",
    "# reshaped = Reshape((28,28,4,1))(inp)     # input_shape=(96,96,3,5) \n",
    "permuted = Permute((2,3,4,1))(inp)\n",
    "last_layer = Lambda(slice, input_shape=(28,28,1,4), output_shape=(28,28,1))(permuted)\n",
    "# x = Permute((4,1,2,3))(noise)\n",
    "x =(ConvLSTM2D(filters=c, kernel_size=(3,3),padding='same',name='conv_lstm1', return_sequences=True))(inp)\n",
    "\n",
    "c1=(BatchNormalization())(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x =(TimeDistributed(MaxPooling2D(pool_size=(2,2))))(c1)\n",
    "\n",
    "x =(ConvLSTM2D(filters=2*c,kernel_size=(3,3),padding='same',name='conv_lstm3',return_sequences=True))(x)\n",
    "c2=(BatchNormalization())(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x =(TimeDistributed(MaxPooling2D(pool_size=(2,2))))(c2)\n",
    "x =(ConvLSTM2D(filters=4*c,kernel_size=(3,3),padding='same',name='conv_lstm4',return_sequences=True))(x)\n",
    "\n",
    "x =(TimeDistributed(UpSampling2D(size=(2, 2))))(x)\n",
    "x =(ConvLSTM2D(filters=4*c,kernel_size=(3,3),padding='same',name='conv_lstm5',return_sequences=True))(x)\n",
    "x =(BatchNormalization())(x)\n",
    "\n",
    "x =(ConvLSTM2D(filters=2*c,kernel_size=(3,3),padding='same',name='conv_lstm6',return_sequences=True))(x)\n",
    "x =(BatchNormalization())(x)\n",
    "x = Add()([c2, x])\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x =(TimeDistributed(UpSampling2D(size=(2, 2))))(x)\n",
    "x =(ConvLSTM2D(filters=c,kernel_size=(3,3),padding='same',name='conv_lstm7',return_sequences=False))(x)\n",
    "x =(BatchNormalization())(x)\n",
    "combined = concatenate([last_layer, x])\n",
    "combined = Conv2D(1, (1,1))(combined)\n",
    "model=Model(inputs=[inp], outputs=[combined])\n",
    "# model=Model(inputs=[inp], outputs=x) \n",
    "\n",
    "# opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=[perceptual_distance])  # adam, binary_crossentropy \n",
    "\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 35\n",
    "batch_size = 16\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "#     callbacks=[early_stopping, reduce_lr],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87279dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying volume maps for example 59340.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select a random example from the validation dataset.\n",
    "example = test_dataset[np.random.choice(range(len(test_dataset)), size=1)[0]]\n",
    "\n",
    "# example = test_dataset[2972]\n",
    "\n",
    "# Construct a figure on which we will visualize the images.\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 8))\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    ax.imshow(np.squeeze(example[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Volume map {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Print information and display the figure.\n",
    "print(f\"Displaying volume maps for example {data_choice}.\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fefb6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first/last ten frames from the example.\n",
    "frames = example[:4, ...]\n",
    "original_frames = example[1:, ...]\n",
    "\n",
    "# Predict a new set\n",
    "new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "# new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "# predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27778714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0faf0c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted map\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Predicted map\")\n",
    "\n",
    "plt.figure(figsize = (4, 4))\n",
    "\n",
    "plt.imshow(np.round(new_prediction[0]*255, 0) , cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5255d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.2"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.round(new_prediction[0]*255, 1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7d63dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(example[-1, ...]*255).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7bc58989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original map\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Original map\")\n",
    "\n",
    "plt.figure(figsize = (4, 4))\n",
    "\n",
    "plt.imshow(example[-1, ...]*255, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e4297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
